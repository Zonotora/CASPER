{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipinfo\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import requests\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "import csv\n",
    "import multiprocessing\n",
    "import json\n",
    "import pycountry\n",
    "import country_converter as coco  #Coco was found to be more accuracte. Pycountry had weird labels for e.g. russia\n",
    "\n",
    "\n",
    "def get_ip():\n",
    "    response = requests.get('https://api64.ipify.org?format=json').json()\n",
    "    return response[\"ip\"]\n",
    "\n",
    "\n",
    "def get_location(ip):\n",
    "    response = requests.get(f'https://ipapi.co/{ip}/json/').json()\n",
    "    location_data = {\n",
    "        \"ip\": ip,\n",
    "        \"city\": response.get(\"city\"),\n",
    "        \"region\": response.get(\"region\"),\n",
    "        \"country\": response.get(\"country_name\")\n",
    "    }\n",
    "    return location_data\n",
    "\n",
    "def get_location_ipinfo(ip_address):\n",
    "    ''' Best one of the three. However, IP requests is limited to the token\n",
    "    '''\n",
    "    try:\n",
    "        access_token = '7dbb53d0419093'\n",
    "        handler = ipinfo.getHandler(access_token)\n",
    "        details = handler.getDetails(ip_address)\n",
    "        if details.country == \"US\": \n",
    "            return details.region\n",
    "        else:\n",
    "            return details.country\n",
    "    except:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ip_locations(df):\n",
    "    df[\"MinIP_loc\"] = np.nan\n",
    "    df[\"otherIP1_loc\"] = np.nan \n",
    "    df[\"otherIP2_loc\"] = np.nan \n",
    "    df[\"otherIP3_loc\"] = np.nan \n",
    "    df[\"otherIP4_loc\"] = np.nan \n",
    "    df[\"otherIP5_loc\"] = np.nan \n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        df.loc[index, \"MinIP_loc\"] = get_location_ipinfo(row[\"MinIP\"])\n",
    "        for i in range(1,6):  \n",
    "            name = f\"otherIP{i}\"\n",
    "            if pd.isna(row[name]):\n",
    "                continue\n",
    "\n",
    "            location = get_location_ipinfo(row[f\"otherIP{i}\"])\n",
    "            df.loc[index, f\"otherIP{i}_loc\"] = location\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prb_location(df_prbs, prb_dic):\n",
    "    '''Returns a dataframe with prb number and their respective country or state \n",
    "    '''\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    df_prbs[\"prb_loc\"] = \"\"\n",
    "    for index, row in df_prbs.iterrows():\n",
    "        prb_number = row[\"prb\"]\n",
    "        long,lat = tuple(prb_dic[prb_number][\"geometry\"][\"coordinates\"])\n",
    "        location = \"\"\n",
    "        try:\n",
    "            location = geolocator.reverse(str(lat) + \",\" + str(long), language = 'en').raw\n",
    "        except: \n",
    "            print(\"timeout at index: \" + str(index))\n",
    "            continue\n",
    "        country = location[\"address\"][\"country\"]\n",
    "        \n",
    "        if country == \"Canada\":\n",
    "            state = location[\"address\"][\"state\"]\n",
    "            df_prbs.loc[index, \"prb_loc\"] = state\n",
    "        elif country == \"United States\":\n",
    "            state = str((location)).split(\",\")[-3]\n",
    "            state = location[\"address\"][\"state\"]\n",
    "            df_prbs.loc[index, \"prb_loc\"] = state\n",
    "        else:\n",
    "            country_code = location[\"address\"][\"country_code\"].upper() \n",
    "            df_prbs.loc[index, \"prb_loc\"] = country_code\n",
    "        if index%1000 == 0:\n",
    "            print(\"AT INDEX:   \" + str(index))\n",
    "    return df_prbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prb_locs(df_edges,pickle_path):\n",
    "\n",
    "    df_prbs_np_arr = df_edges[\"prb\"].unique()\n",
    "    df_prbs = pd.DataFrame(df_prbs_np_arr, columns=[\"prb\"])\n",
    "\n",
    "    with open(pickle_path, 'rb') as handle:\n",
    "        prb_dic = pickle.load(handle)\n",
    "        df_prb_loc = prb_location(df_prbs, prb_dic)\n",
    "        df_prbs = df_prb_loc\n",
    "        #df_prb_loc.to_csv(r\"api\\latencies\\prbs_with_locations.csv\", index = False)\n",
    "    #return df_prbs\n",
    "    return df_prb_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_prb_locs_with_ip_locs(df_prb_loc, df_with_ip_locs):\n",
    "    ''' Takes the csv with prbs and their respecitve locations to merge with the file containing ip locations\n",
    "    ''' \n",
    "    prb_to_loc = {}\n",
    "    for index, row in df_prb_loc.iterrows():\n",
    "        prb_to_loc[row[\"prb\"]] = row[\"prb_loc\"]\n",
    "    \n",
    "    df_with_ip_locs[\"prb_loc\"] = \"\"\n",
    "    for index, row in df_with_ip_locs.iterrows(): \n",
    "        df_with_ip_locs.loc[index,\"prb_loc\"] = prb_to_loc[row[\"prb\"]]\n",
    "\n",
    "    return df_with_ip_locs\n",
    "\n",
    "def reorder_columns_of_final_df(merged_df):\n",
    "    ''' Reformats the file by column order\n",
    "    '''\n",
    "    cols = [\n",
    "        \"prb\" , \"prb_loc\",\n",
    "        \"MinIP\", \"MinIP_loc\", \"Minlatency\",\n",
    "        \"otherIP1\", \"otherIP1_loc\", \"otherlatency1\",\n",
    "        \"otherIP2\", \"otherIP2_loc\", \"otherlatency2\",\n",
    "        \"otherIP3\", \"otherIP3_loc\", \"otherlatency3\",\n",
    "        \"otherIP4\", \"otherIP4_loc\", \"otherlatency4\",\n",
    "        \"otherIP5\", \"otherIP5_loc\", \"otherlatency5\",\n",
    "        ]\n",
    "\n",
    "    merged_df = merged_df[cols]\n",
    "    \n",
    "    merged_df = merged_df.rename({\n",
    "        'otherIP1': 'IP1', \n",
    "        'otherIP2': 'IP2', \n",
    "        'otherIP3': 'IP3', \n",
    "        'otherIP4': 'IP4', \n",
    "        'otherIP5': 'IP5',\n",
    "        'otherIP1_loc': 'IP1_loc', \n",
    "        'otherIP2_loc': 'IP2_loc', \n",
    "        'otherIP3_loc': 'IP3_loc', \n",
    "        'otherIP4_loc': 'IP4_loc', \n",
    "        'otherIP5_loc': 'IP5_loc',\n",
    "        'otherlatency1': 'latency1', \n",
    "        'otherlatency2': 'latency2',\n",
    "        'otherlatency3': 'latency3',\n",
    "        'otherlatency4': 'latency4',\n",
    "        'otherlatency5': 'latency5'\n",
    "        }, axis='columns')\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_country_code(df):\n",
    "    ''' Converts non-'North American' countries to country code\n",
    "    '''\n",
    "    cc = coco.CountryConverter()\n",
    "    #df = df.apply(lambda x: pycountry.countries.get(name=str(x)) if pycountry.countries.get(name=str(x)) != None else print(x))\n",
    "    df = df.apply(lambda x: coco.convert(names=x, to='ISO2', not_found = x) if coco.convert(names=x, to='ISO2', not_found = None) != None else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adj_mtx(edge_path, locations):\n",
    "    '''Creates an adjacency matrix and returns it to later be saved with picke\n",
    "    '''\n",
    "    df_adj = pd.DataFrame(columns=locations, index=locations, dtype = object)\n",
    "\n",
    "    df_edges = pd.read_csv(edge_path, index_col=False)\n",
    "    cols = [\"IP1_loc\", \"IP2_loc\", \"IP3_loc\", \"IP4_loc\", \"IP5_loc\", \"MinIP_loc\"]\n",
    "    \n",
    "    for index, row in df_edges.iterrows():\n",
    "        from_loc = row[\"prb_loc\"]\n",
    "        # skip if datacenter's location not sought after\n",
    "        if from_loc not in locations:\n",
    "            continue\n",
    "        for col in cols: \n",
    "            to_loc = row[col]     \n",
    "            # if user's request location not sought after  \n",
    "            if to_loc not in locations:\n",
    "                continue  \n",
    "            col_idx = df_edges.columns.get_loc(col)\n",
    "            latency = row.iloc[col_idx+1]    \n",
    "            saved_latencies = df_adj.loc[from_loc,to_loc]\n",
    "            if np.isnan(saved_latencies).all():\n",
    "                df_adj.loc[from_loc,to_loc] = list([float(latency)])\n",
    "                df_adj.loc[to_loc,from_loc] = list([float(latency)])\n",
    "            else:\n",
    "                df_adj.loc[from_loc,to_loc].append(float(latency))\n",
    "                df_adj.loc[to_loc, from_loc].append(float(latency))\n",
    "    return df_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_regions(df):\n",
    "    ''' Returns all mentioned locations in edge latency file\n",
    "    '''\n",
    "    df_locs = pd.concat([df[\"prb_loc\"], df[\"MinIP_loc\"], df[\"IP1_loc\"], df[\"IP2_loc\"], df[\"IP3_loc\"], df[\"IP4_loc\"], df[\"IP5_loc\"]])\n",
    "    return df_locs.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def no_empty_cells(df):\n",
    "    no = 0\n",
    "    for index, row in df.iterrows():\n",
    "        no += row.isna().sum()\n",
    "    return no\n",
    "\n",
    "def no_all_latencies(df):\n",
    "    no = 0\n",
    "    for index, row in df.iterrows():\n",
    "        no += row.notna().count()\n",
    "    return no\n",
    "\n",
    "def no_all_latencies2(df):\n",
    "    no = 0\n",
    "    for index, row in df.iterrows():\n",
    "        no += row.notna().astype(str).str.len().sum()\n",
    "    return no\n",
    "\n",
    "def all_latencies_dict(df):\n",
    "    no = defaultdict(lambda:0)\n",
    "    for index, row in df.iterrows():\n",
    "        print(row.isna())\n",
    "        no[index] += row.isna().count()\n",
    "    return no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prb_loc(prb_id):\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    response = requests.get(f\"https://atlas.ripe.net/api/v2/probes/{prb_id}/?format=json\")\n",
    "    resp_json = json.loads(response.content.decode(\"utf-8\"))\n",
    "    long, lat = tuple(resp_json[\"geometry\"][\"coordinates\"])\n",
    "    \n",
    "    location = geolocator.reverse(str(lat) + \",\" + str(long), language = 'en')\n",
    "\n",
    "    if location == None:\n",
    "        print(\"None at location for prb: \" + str(prb_id))\n",
    "        return np.nan\n",
    "\n",
    "    country = location.raw[\"address\"][\"country\"]\n",
    "\n",
    "    if country in [\"United States\", \"Canada\"]:\n",
    "        state = location.raw[\"address\"][\"state\"]\n",
    "        return state\n",
    "    else: \n",
    "        country_code = location.raw[\"address\"][\"country_code\"].upper() \n",
    "        return country_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_locs(edge_df, cloud_df):\n",
    "    \"\"\" As edge_df has prbs with corresponding locations, we merge them to avoid time-consuming queries on prb_id\n",
    "    \"\"\"\n",
    "    edge_df = edge_df[[\"prb\", \"prb_loc\"]]\n",
    "    cloud_df = cloud_df.merge(edge_df, how=\"left\", right_index = False, on = \"prb\")\n",
    "    prb_locs = cloud_df.pop(\"prb_loc\")\n",
    "    cloud_df.insert(1, \"prb_loc\", prb_locs)\n",
    "    return cloud_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_cloud():\n",
    "    regions = pd.read_json(r\"..\\api\\latencies\\cloud_regions_na.json\", orient= \"records\", dtype = dict)\n",
    "    return regions[\"locations\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_flattened():\n",
    "    locations = list(translate_cloud().values())\n",
    "    # flatten \n",
    "    locations = [location for sub_locations in locations for location in sub_locations]\n",
    "    # remove duplicates\n",
    "    return list(set(locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label_locations(cloud_df):\n",
    "    # To run multiprocessing\n",
    "    import pandas as pd\n",
    "    region_cols = [\"minLabel\"] + [f\"label.{i}\" for i in range(1,68)]\n",
    "    for col in region_cols:\n",
    "        cloud_df[col + \"_loc\"] = pd.NA\n",
    "    \n",
    "    name_lookup = translate_cloud()\n",
    "\n",
    "    for index, row in cloud_df.iterrows():\n",
    "        from_loc = row[\"prb_loc\"]\n",
    "        if not from_loc in values_flattened():\n",
    "            continue\n",
    "        print(from_loc)\n",
    "        for col in region_cols:\n",
    "            loc_str = col + \"_loc\"\n",
    "            parsed_loc = row[loc_str]\n",
    "            if not pd.isnull(parsed_loc) or pd.isnull(row[col]):\n",
    "                continue\n",
    "            unparsed_loc = row[col].replace(\".csv\", \"\")\n",
    "            if unparsed_loc in name_lookup.keys():\n",
    "                names = name_lookup[unparsed_loc]\n",
    "                if len(names) == 1:\n",
    "                    cloud_df.loc[index, loc_str] = names[0]\n",
    "                else: \n",
    "                    cloud_df.loc[index, loc_str] = names[0] \n",
    "\n",
    "                    index_append = cloud_df.shape[0]\n",
    "                    index_current_col = cloud_df.columns.get_loc(col) - 1\n",
    "                    #latency_value = cloud_df.iloc[index, index_current_col]\n",
    "                    latency_value = row.iloc[index_current_col]\n",
    "\n",
    "                    # Split the names and append last string to last column to process later\n",
    "                    cloud_df.loc[index_append] = pd.NA \n",
    "                    cloud_df.loc[index_append, \"prb\"] = row[\"prb\"]\n",
    "                    cloud_df.loc[index_append, \"prb_loc\"] = row[\"prb_loc\"]\n",
    "                    cloud_df.loc[index_append, \"minLabel\"] = unparsed_loc\n",
    "                    cloud_df.loc[index_append, \"minLabel_loc\"] = names[1]\n",
    "                    cloud_df.loc[index_append, \"minMedian\"] = latency_value\n",
    "\n",
    "                    # No need for minLabel_loc, will be processed later\n",
    "        if index%1000 == 0:\n",
    "            print(\"AT INDEX:   \" + str(index))\n",
    "    return cloud_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8569"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3\n",
    "80\n",
    "8569\n",
    "8569\n",
    "4\n",
    "22\n",
    "8569\n",
    "8569\n",
    "5\n",
    "50\n",
    "8569\n",
    "8569\n",
    "...\n",
    "8570\n",
    "50\n",
    "8569\n",
    "8569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adj_mtx2(cloud_path, locations):\n",
    "    '''Creates an adjacency matrix and returns it to later be saved with picke\n",
    "    '''\n",
    "    df_adj = pd.DataFrame(columns=locations, index=locations, dtype = object)\n",
    "\n",
    "    df_edges = pd.read_csv(cloud_path, index_col=False)\n",
    "    cols = [\"prb_loc\", \"minLabel_loc\"] + [f\"label.{i}_loc\" for i in range(1,68)]\n",
    "    \n",
    "    for index, row in df_edges.iterrows():\n",
    "        from_loc = row[\"prb_loc\"]\n",
    "        # skip if datacenter's location not sought after\n",
    "        if from_loc not in locations:\n",
    "            continue\n",
    "        for col in cols: \n",
    "            to_loc = row[col]     \n",
    "            # if user's request location not sought after  \n",
    "            if to_loc not in locations:\n",
    "                continue  \n",
    "            label = col.replace(\"_loc\", \"\")\n",
    "            label_idx = df_edges.columns.get_loc(label)\n",
    "            latency = row.iloc[label_idx-1]    \n",
    "            saved_latencies = df_adj.loc[from_loc,to_loc]\n",
    "            # true if saved latencies is empty list\n",
    "            if not isinstance(saved_latencies, list):\n",
    "                df_adj.loc[from_loc,to_loc] = list([float(latency)])\n",
    "                df_adj.loc[to_loc,from_loc] = list([float(latency)])\n",
    "            else:\n",
    "                df_adj.loc[from_loc,to_loc].append(float(latency))\n",
    "                df_adj.loc[to_loc, from_loc].append(float(latency))\n",
    "    return df_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_edge_cloud_latencies(edge_df, cloud_df): \n",
    "    cloud_locs = list(cloud_df.index)\n",
    "    edge_locs = list(edge_df.index)\n",
    "    for loc1, row in cloud_df.iterrows():\n",
    "        for loc2, col in zip(cloud_locs, row):\n",
    "            if loc2 not in edge_locs: \n",
    "                edge_df[loc2] = \"\"\n",
    "                #edge_df.reindex(edge_df.index.values.tolist()+[loc])\n",
    "                edge_df.loc[loc2] = \"\"\n",
    "                edge_df.loc[loc2, loc1] = cloud_df.loc[loc2, loc1]\n",
    "                edge_df.loc[loc1, loc2] = cloud_df.loc[loc2, loc1]\n",
    "            else:                 \n",
    "                edge_df.loc[loc1, loc2] = cloud_df.loc[loc2, loc1]\n",
    "                edge_df.loc[loc2, loc1] = cloud_df.loc[loc2, loc1]\n",
    "\n",
    "    return edge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mtx_info(df, regions = \"\", type = \"\"):\n",
    "    print(\"Number of regions: \" + str(len(regions)))\n",
    "\n",
    "    print(\"N.o. all latencies: \" + str(no_all_latencies2(df)))\n",
    "    #print(all_latencies_dict(df))\n",
    "    if regions != \"\":\n",
    "        print(\"N.o. missing datapoints: \" + str(no_empty_cells(df)) + \" out of \" + str(len(regions)*len(regions)))\n",
    "    if type == \"cloud\":\n",
    "        print(no_all_latencies2(df))\n",
    "    if type == \"edge\":\n",
    "        print(no_all_latencies(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This extracts probe id and maps it to a location\n",
    "\n",
    "# df_edges = pd.read_csv(r\"api\\latencies\\edge.csv\", index_col= False)\n",
    "# df_prb_locs = extract_prb_locs(df_edges, picke_path = r'api\\latencies\\probes_clean.pickle')\n",
    "# df_prb_locs.to_csv(r\"api\\latencies\\prbs_with_locations.csv\", index = False)\n",
    "\n",
    "\n",
    "# timeout at index: 7775\n",
    "# AT INDEX:   8000\n",
    "# timeout at index: 8215\n",
    "\n",
    "### This assign a country code to non us/canada countries. they use states instead\n",
    "\n",
    "#df_prbs = pd.read_csv(r\"api\\latencies\\prbs_with_locations.csv\", index_col= False)\n",
    "#df_prbs[\"prb_loc\"] = convert_country_code(df_prbs[\"prb_loc\"])\n",
    "#df_prbs.to_csv(r\"api\\latencies\\prbs_with_locations_coco.csv\", index = False)\n",
    "\n",
    "### THIS adds location to the fields [MinIP, OtherIP{1,2,3,4,5}]\n",
    "\n",
    "#df_with_ip_locs = add_ip_locations(df_edges)\n",
    "#df_with_ip_locs.to_csv(r\"api\\latencies\\edge_with_ip_locs.csv\", index= False)\n",
    "\n",
    "\n",
    "### BELOW Is to merge files and formatting\n",
    "\n",
    "# df_prb_loc = pd.read_csv(r\"api\\latencies\\prbs_with_locations.csv\", index_col = False)\n",
    "# df_with_ip_locs = pd.read_csv(r\"api\\latencies\\edge_processed10.csv\", index_col = False)\n",
    "\n",
    "# df_merged = merge_prb_locs_with_ip_locs(df_prb_loc, df_with_ip_locs)\n",
    "\n",
    "# df_merged_formated = reorder_columns_of_final_df(df_merged)\n",
    "# df_merged_formated.to_csv(r\"api\\latencies\\edge_feat_locations.csv\", index = False)\n",
    "\n",
    "### Creates adjacency matrix out of the edge latencies\n",
    "\n",
    "# df = pd.read_csv(r\"..\\api\\latencies\\edge_feat_locations.csv\", index_col=False)\n",
    "# regions = get_all_regions(df)\n",
    "# # # Filter out NaN and regions\n",
    "# print(regions)\n",
    "# na = [region for region in regions if type(region) == str and len(region) > 2]\n",
    "# na.remove(\"Guam\")\n",
    "# na.remove(\"Prince Edward Island\")\n",
    "# na.remove(\"United States Virgin Islands\")\n",
    "\n",
    "# eu = [region for region in regions if type(region) == str and len(region) < 3]\n",
    "\n",
    "# edge_mtx = create_adj_mtx(r\"..\\api\\latencies\\edge_feat_locations.csv\", na)\n",
    "# edge_mtx.to_pickle(r\"..\\api\\latencies\\adjacency_mtrx.pickle\")\n",
    "\n",
    "# print_mtx_info(edge_mtx, na, type=\"edge\")\n",
    "\n",
    "# edge_mtx.to_csv(r\"..\\api\\latencies\\edge_feat_locations_na.csv\")\n",
    "\n",
    "# ## Add locations to cloud_data \n",
    "\n",
    "# cloud_df = pd.read_csv(r\"..\\api\\latencies\\cloud.csv\")\n",
    "# edge_df = pd.read_csv(r\"..\\api\\latencies\\edge_feat_locations.csv\")\n",
    "# cloud_with_locs = merge_locs(edge_df, cloud_df)\n",
    "\n",
    "# print(\"This many prb_locs couldn't resolved by merge: \" + str(cloud_with_locs[\"prb_loc\"].isna().sum()))\n",
    "\n",
    "# missing_locs = cloud_with_locs[cloud_with_locs[\"prb_loc\"].isna()]\n",
    "# for index, row in missing_locs.iterrows():\n",
    "#     cloud_with_locs.loc[index, \"prb_loc\"] = get_prb_loc(row[\"prb\"])\n",
    "\n",
    "# print(\"This many prb_locs couldn't resolved after applying lookups: \" + str(cloud_with_locs[\"prb_loc\"].isna().sum()))\n",
    "\n",
    "# cloud_with_locs = cloud_with_locs[cloud_with_locs[\"prb_loc\"].notna()]\n",
    "# cloud_with_locs.to_csv(r\"..\\api\\latencies\\cloud_feat_locations.csv\", index= False)\n",
    "\n",
    "# # Convert \"blabla.csv\" to real names\n",
    "# cloud_df_with_labels = add_label_locations(cloud_with_locs)\n",
    "# cloud_df_with_labels.to_csv(r\"..\\api\\latencies\\cloud_feats_real_locations.csv\")\n",
    "\n",
    "# locations = values_flattened()\n",
    "\n",
    "# cloud_mtx = create_adj_mtx2(r\"..\\api\\latencies\\cloud_feats_real_locations.csv\", locations)\n",
    "\n",
    "# print_mtx_info(cloud_mtx, na, type=\"cloud\")\n",
    "\n",
    "\n",
    "# print(\"Number of regions in NA: \" + str(len(locations)))\n",
    "# print(\"N.o. all latencies: \" + str(no_all_latencies2(cloud_mtx)))\n",
    "# #print(all_latencies_dict(mtx))\n",
    "# print(\"N.o. missing datapoints: \" + str(no_empty_cells(cloud_mtx)) + \" out of \" + str(len(locations)*len(locations)))\n",
    "\n",
    "# cloud_mtx.to_pickle(r\"..\\api\\latencies\\adjacency_mtrx_cloud.pickle\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiprocesspandas\n",
    "\n",
    "#cloud_with_locs.apply_parallel(add_label_locations, num_processes=4, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['New Brunswick', 'Washington', 'California', 'Virginia', 'Ohio',\n",
      "       'Louisiana', 'Wisconsin', 'Mississippi', 'Texas', 'Delaware', 'Ontario',\n",
      "       'Alberta', 'North Carolina', 'Massachusetts', 'Connecticut', 'Florida',\n",
      "       'Colorado', 'Michigan', 'Indiana', 'Iowa', 'Saskatchewan', 'Oklahoma',\n",
      "       'Tennessee', 'Georgia', 'Maine', 'Nebraska', 'New York', 'Idaho',\n",
      "       'British Columbia', 'Manitoba', 'New Jersey', 'Minnesota', 'Oregon',\n",
      "       'Pennsylvania', 'Utah', 'Arizona', 'Rhode Island', 'Quebec',\n",
      "       'Newfoundland and Labrador', 'New Mexico', 'Arkansas', 'Maryland',\n",
      "       'Illinois', 'Kentucky', 'District of Columbia', 'New Hampshire',\n",
      "       'Missouri', 'Nova Scotia', 'Nevada', 'Kansas', 'North Dakota',\n",
      "       'Vermont', 'South Carolina', 'Puerto Rico', 'Alaska', 'Hawaii',\n",
      "       'West Virginia', 'Montana', 'Northwest Territories', 'South Dakota',\n",
      "       'Alabama', 'Wyoming', 'Yukon', 'Washington, D.C.', 'North Virginia'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New Brunswick</th>\n",
       "      <th>Washington</th>\n",
       "      <th>California</th>\n",
       "      <th>Virginia</th>\n",
       "      <th>Ohio</th>\n",
       "      <th>Louisiana</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>Mississippi</th>\n",
       "      <th>Texas</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>...</th>\n",
       "      <th>Hawaii</th>\n",
       "      <th>West Virginia</th>\n",
       "      <th>Montana</th>\n",
       "      <th>Northwest Territories</th>\n",
       "      <th>South Dakota</th>\n",
       "      <th>Alabama</th>\n",
       "      <th>Wyoming</th>\n",
       "      <th>Yukon</th>\n",
       "      <th>Washington, D.C.</th>\n",
       "      <th>North Virginia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New Brunswick</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[69.0, 10.139825, 10.139825, 180.0, 180.0, 9.1...</td>\n",
       "      <td>[29.202135, 35.159335, 27.645745, 19.37087, 36...</td>\n",
       "      <td>[82.942292, 66.181285, 84.709775, 75.23258, 75...</td>\n",
       "      <td>[60.256055, 94.605435, 94.780135, 52.91472, 60...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[59.04227, 62.56105, 49.289265, 62.324165, 56....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[93.171645]</td>\n",
       "      <td>[29.628005, 44.27234]</td>\n",
       "      <td>[22.22458, 23.069665, 21.51524]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[23.67485, 23.714485, 24.20839, 24.5869, 23.20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[64.185625, 85.30906, 83.17924, 68.371295, 81....</td>\n",
       "      <td>[78.82073, 89.709205, 90.809645, 76.14033, 90....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[29.202135, 35.159335, 27.645745, 19.37087, 36...</td>\n",
       "      <td>[71.0, 84.0, 84.0, 90.0, 90.0, 107.0, 107.0, 2...</td>\n",
       "      <td>[92.194041, 75.899475, 84.54834, 74.448065, 77...</td>\n",
       "      <td>[82.364125, 85.271905, 70.71036, 70.85003, 67....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[13.396625, 9.066555]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[53.21958, 54.88945, 41.642655, 45.46812, 46.7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[48.03675, 49.73371, 49.861415, 68.899845, 71....</td>\n",
       "      <td>[12.108515, 10.154895]</td>\n",
       "      <td>[75.05065, 75.1289925, 130.427795, 54.67809, 5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[82.28963, 78.79356, 62.062335, 68.0653, 65.47...</td>\n",
       "      <td>[67.468035, 80.563635, 61.13136, 70.36708, 69....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[82.942292, 66.181285, 84.709775, 75.23258, 75...</td>\n",
       "      <td>[92.194041, 75.899475, 84.54834, 74.448065, 77...</td>\n",
       "      <td>[4.0, 9.527875, 9.527875, 17.795916, 17.795916...</td>\n",
       "      <td>[24.817875, 19.69237, 22.23409, 18.937055, 27....</td>\n",
       "      <td>[22.99056, 23.233545, 13.67115, 18.18783, 26.9...</td>\n",
       "      <td>[46.39941, 48.11897, 35.135105, 39.439455, 42....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[45.95525, 51.963917, 34.579945, 46.642255, 42...</td>\n",
       "      <td>[8.07943, 14.73068, 14.742405, 14.828805, 15.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[34.85445]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[48.78525, 66.86637]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[12.257166, 11.028055, 4.201585, 11.88441, 9.6...</td>\n",
       "      <td>[13.433125, 9.4397, 16.152855, 2.635205, 11.67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[60.256055, 94.605435, 94.780135, 52.91472, 60...</td>\n",
       "      <td>[82.364125, 85.271905, 70.71036, 70.85003, 67....</td>\n",
       "      <td>[24.817875, 19.69237, 22.23409, 18.937055, 27....</td>\n",
       "      <td>[224.0, 19.357735, 19.357735, 1191.0, 1191.0, ...</td>\n",
       "      <td>[32.96968, 54.99881, 32.89856]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[41.62104, 42.98251, 53.53678, 33.98193, 52.68...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[23.010375, 34.769245, 38.911185, 29.1559, 28....</td>\n",
       "      <td>[29.99192, 36.29896, 35.98119, 33.19634, 21.98...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3.32026, 5.40437, 19.8191, 3.27144]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[12.588695]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[23.67485, 23.714485, 24.20839, 24.5869, 23.20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yukon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington, D.C.</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[64.185625, 85.30906, 83.17924, 68.371295, 81....</td>\n",
       "      <td>[82.28963, 78.79356, 62.062335, 68.0653, 65.47...</td>\n",
       "      <td>[12.257166, 11.028055, 4.201585, 11.88441, 9.6...</td>\n",
       "      <td>[23.010375, 34.769245, 38.911185, 29.1559, 28....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[38.24714, 40.03631, 44.369645, 40.81574, 44.9...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[33.967305, 37.970095, 38.703295, 39.13436, 32...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[12.588695]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Virginia</th>\n",
       "      <td></td>\n",
       "      <td>[78.82073, 89.709205, 90.809645, 76.14033, 90....</td>\n",
       "      <td>[67.468035, 80.563635, 61.13136, 70.36708, 69....</td>\n",
       "      <td>[13.433125, 9.4397, 16.152855, 2.635205, 11.67...</td>\n",
       "      <td>[29.99192, 36.29896, 35.98119, 33.19634, 21.98...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[38.42919, 39.519825, 45.18897, 44.32643, 45.7...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 New Brunswick  \\\n",
       "New Brunswick              NaN   \n",
       "Washington                 NaN   \n",
       "California                 NaN   \n",
       "Virginia                   NaN   \n",
       "Ohio                       NaN   \n",
       "...                        ...   \n",
       "Alabama                    NaN   \n",
       "Wyoming                    NaN   \n",
       "Yukon                      NaN   \n",
       "Washington, D.C.           NaN   \n",
       "North Virginia                   \n",
       "\n",
       "                                                         Washington  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington        [69.0, 10.139825, 10.139825, 180.0, 180.0, 9.1...   \n",
       "California        [29.202135, 35.159335, 27.645745, 19.37087, 36...   \n",
       "Virginia          [82.942292, 66.181285, 84.709775, 75.23258, 75...   \n",
       "Ohio              [60.256055, 94.605435, 94.780135, 52.91472, 60...   \n",
       "...                                                             ...   \n",
       "Alabama                                                         NaN   \n",
       "Wyoming           [23.67485, 23.714485, 24.20839, 24.5869, 23.20...   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.  [64.185625, 85.30906, 83.17924, 68.371295, 81....   \n",
       "North Virginia    [78.82073, 89.709205, 90.809645, 76.14033, 90....   \n",
       "\n",
       "                                                         California  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington        [29.202135, 35.159335, 27.645745, 19.37087, 36...   \n",
       "California        [71.0, 84.0, 84.0, 90.0, 90.0, 107.0, 107.0, 2...   \n",
       "Virginia          [92.194041, 75.899475, 84.54834, 74.448065, 77...   \n",
       "Ohio              [82.364125, 85.271905, 70.71036, 70.85003, 67....   \n",
       "...                                                             ...   \n",
       "Alabama                                                         NaN   \n",
       "Wyoming                                                         NaN   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.  [82.28963, 78.79356, 62.062335, 68.0653, 65.47...   \n",
       "North Virginia    [67.468035, 80.563635, 61.13136, 70.36708, 69....   \n",
       "\n",
       "                                                           Virginia  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington        [82.942292, 66.181285, 84.709775, 75.23258, 75...   \n",
       "California        [92.194041, 75.899475, 84.54834, 74.448065, 77...   \n",
       "Virginia          [4.0, 9.527875, 9.527875, 17.795916, 17.795916...   \n",
       "Ohio              [24.817875, 19.69237, 22.23409, 18.937055, 27....   \n",
       "...                                                             ...   \n",
       "Alabama                                                         NaN   \n",
       "Wyoming                                                         NaN   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.  [12.257166, 11.028055, 4.201585, 11.88441, 9.6...   \n",
       "North Virginia    [13.433125, 9.4397, 16.152855, 2.635205, 11.67...   \n",
       "\n",
       "                                                               Ohio  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington        [60.256055, 94.605435, 94.780135, 52.91472, 60...   \n",
       "California        [82.364125, 85.271905, 70.71036, 70.85003, 67....   \n",
       "Virginia          [24.817875, 19.69237, 22.23409, 18.937055, 27....   \n",
       "Ohio              [224.0, 19.357735, 19.357735, 1191.0, 1191.0, ...   \n",
       "...                                                             ...   \n",
       "Alabama                                                         NaN   \n",
       "Wyoming                                                         NaN   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.  [23.010375, 34.769245, 38.911185, 29.1559, 28....   \n",
       "North Virginia    [29.99192, 36.29896, 35.98119, 33.19634, 21.98...   \n",
       "\n",
       "                                                          Louisiana  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington                                                      NaN   \n",
       "California                                                      NaN   \n",
       "Virginia          [22.99056, 23.233545, 13.67115, 18.18783, 26.9...   \n",
       "Ohio                                 [32.96968, 54.99881, 32.89856]   \n",
       "...                                                             ...   \n",
       "Alabama                        [3.32026, 5.40437, 19.8191, 3.27144]   \n",
       "Wyoming                                                         NaN   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.                                                NaN   \n",
       "North Virginia                                                        \n",
       "\n",
       "                                                          Wisconsin  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington                                                      NaN   \n",
       "California                                    [13.396625, 9.066555]   \n",
       "Virginia          [46.39941, 48.11897, 35.135105, 39.439455, 42....   \n",
       "Ohio                                                            NaN   \n",
       "...                                                             ...   \n",
       "Alabama                                                         NaN   \n",
       "Wyoming                                                         NaN   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.                                                NaN   \n",
       "North Virginia                                                        \n",
       "\n",
       "                 Mississippi  \\\n",
       "New Brunswick            NaN   \n",
       "Washington               NaN   \n",
       "California               NaN   \n",
       "Virginia                 NaN   \n",
       "Ohio                     NaN   \n",
       "...                      ...   \n",
       "Alabama                  NaN   \n",
       "Wyoming                  NaN   \n",
       "Yukon                    NaN   \n",
       "Washington, D.C.         NaN   \n",
       "North Virginia                 \n",
       "\n",
       "                                                              Texas  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington        [59.04227, 62.56105, 49.289265, 62.324165, 56....   \n",
       "California        [53.21958, 54.88945, 41.642655, 45.46812, 46.7...   \n",
       "Virginia          [45.95525, 51.963917, 34.579945, 46.642255, 42...   \n",
       "Ohio              [41.62104, 42.98251, 53.53678, 33.98193, 52.68...   \n",
       "...                                                             ...   \n",
       "Alabama                                                         NaN   \n",
       "Wyoming                                                         NaN   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.  [38.24714, 40.03631, 44.369645, 40.81574, 44.9...   \n",
       "North Virginia    [38.42919, 39.519825, 45.18897, 44.32643, 45.7...   \n",
       "\n",
       "                                                           Delaware  ...  \\\n",
       "New Brunswick                                                   NaN  ...   \n",
       "Washington                                                      NaN  ...   \n",
       "California                                                      NaN  ...   \n",
       "Virginia          [8.07943, 14.73068, 14.742405, 14.828805, 15.0...  ...   \n",
       "Ohio                                                            NaN  ...   \n",
       "...                                                             ...  ...   \n",
       "Alabama                                                         NaN  ...   \n",
       "Wyoming                                                         NaN  ...   \n",
       "Yukon                                                           NaN  ...   \n",
       "Washington, D.C.                                                NaN  ...   \n",
       "North Virginia                                                       ...   \n",
       "\n",
       "                                                             Hawaii  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington                                              [93.171645]   \n",
       "California        [48.03675, 49.73371, 49.861415, 68.899845, 71....   \n",
       "Virginia                                                        NaN   \n",
       "Ohio                                                            NaN   \n",
       "...                                                             ...   \n",
       "Alabama                                                         NaN   \n",
       "Wyoming                                                         NaN   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.                                                NaN   \n",
       "North Virginia                                                        \n",
       "\n",
       "                                                      West Virginia  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington                                    [29.628005, 44.27234]   \n",
       "California                                   [12.108515, 10.154895]   \n",
       "Virginia                                                 [34.85445]   \n",
       "Ohio                                                            NaN   \n",
       "...                                                             ...   \n",
       "Alabama                                                         NaN   \n",
       "Wyoming                                                         NaN   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.  [33.967305, 37.970095, 38.703295, 39.13436, 32...   \n",
       "North Virginia                                                        \n",
       "\n",
       "                                                            Montana  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington                          [22.22458, 23.069665, 21.51524]   \n",
       "California        [75.05065, 75.1289925, 130.427795, 54.67809, 5...   \n",
       "Virginia                                                        NaN   \n",
       "Ohio                                                            NaN   \n",
       "...                                                             ...   \n",
       "Alabama                                                         NaN   \n",
       "Wyoming                                                         NaN   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.                                                NaN   \n",
       "North Virginia                                                        \n",
       "\n",
       "                 Northwest Territories          South Dakota      Alabama  \\\n",
       "New Brunswick                      NaN                   NaN          NaN   \n",
       "Washington                         NaN                   NaN          NaN   \n",
       "California                         NaN                   NaN          NaN   \n",
       "Virginia                           NaN  [48.78525, 66.86637]          NaN   \n",
       "Ohio                               NaN                   NaN          NaN   \n",
       "...                                ...                   ...          ...   \n",
       "Alabama                            NaN                   NaN          NaN   \n",
       "Wyoming                            NaN                   NaN          NaN   \n",
       "Yukon                              NaN                   NaN          NaN   \n",
       "Washington, D.C.                   NaN                   NaN  [12.588695]   \n",
       "North Virginia                                                              \n",
       "\n",
       "                                                            Wyoming Yukon  \\\n",
       "New Brunswick                                                   NaN   NaN   \n",
       "Washington        [23.67485, 23.714485, 24.20839, 24.5869, 23.20...   NaN   \n",
       "California                                                      NaN   NaN   \n",
       "Virginia                                                        NaN   NaN   \n",
       "Ohio                                                            NaN   NaN   \n",
       "...                                                             ...   ...   \n",
       "Alabama                                                         NaN   NaN   \n",
       "Wyoming                                                         NaN   NaN   \n",
       "Yukon                                                           NaN   NaN   \n",
       "Washington, D.C.                                                NaN   NaN   \n",
       "North Virginia                                                              \n",
       "\n",
       "                                                   Washington, D.C.  \\\n",
       "New Brunswick                                                   NaN   \n",
       "Washington        [64.185625, 85.30906, 83.17924, 68.371295, 81....   \n",
       "California        [82.28963, 78.79356, 62.062335, 68.0653, 65.47...   \n",
       "Virginia          [12.257166, 11.028055, 4.201585, 11.88441, 9.6...   \n",
       "Ohio              [23.010375, 34.769245, 38.911185, 29.1559, 28....   \n",
       "...                                                             ...   \n",
       "Alabama                                                 [12.588695]   \n",
       "Wyoming                                                         NaN   \n",
       "Yukon                                                           NaN   \n",
       "Washington, D.C.                                                NaN   \n",
       "North Virginia                                                  NaN   \n",
       "\n",
       "                                                     North Virginia  \n",
       "New Brunswick                                                        \n",
       "Washington        [78.82073, 89.709205, 90.809645, 76.14033, 90....  \n",
       "California        [67.468035, 80.563635, 61.13136, 70.36708, 69....  \n",
       "Virginia          [13.433125, 9.4397, 16.152855, 2.635205, 11.67...  \n",
       "Ohio              [29.99192, 36.29896, 35.98119, 33.19634, 21.98...  \n",
       "...                                                             ...  \n",
       "Alabama                                                              \n",
       "Wyoming                                                              \n",
       "Yukon                                                                \n",
       "Washington, D.C.                                                NaN  \n",
       "North Virginia                                                  NaN  \n",
       "\n",
       "[65 rows x 65 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge_edge_cloud_latencies(mtrx_df, cloud_mtx)\n",
    "merge_edge_cloud_latencies(edge_mtx, cloud_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud_df = pd.read_csv(r\"..\\api\\latencies\\cloud.csv\")\n",
    "# edge_df = pd.read_csv(r\"..\\api\\latencies\\edge_feat_locations.csv\")\n",
    "# cloud_with_locs = merge_locs(edge_df, cloud_df).tail(100)\n",
    "# missing_locs = cloud_with_locs[cloud_with_locs[\"prb_loc\"].isna()]\n",
    "# for index, row in missing_locs.iterrows():\n",
    "#     cloud_with_locs.loc[index, \"prb_loc\"] = get_prb_loc(row[\"prb\"])\n",
    "\n",
    "# cloud_with_locs.to_csv(r\"..\\api\\latencies\\testing4.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PL', 'NL', 'DE', 'KE', 'Virginia', 'GB', 'FR', 'AT', 'LK', 'CZ',\n",
       "       'HT', 'AU', 'TT', 'FI', 'MX', 'Oklahoma', 'EE', 'CY', 'NO', 'SE',\n",
       "       'LU', 'HU', 'RU', 'Michigan', 'South Carolina', 'Texas', 'LV',\n",
       "       'Georgia', 'Illinois', 'NZ', 'New York', 'North Carolina',\n",
       "       'Quebec', 'New Jersey', 'LT', 'Wisconsin', 'CL', 'Washington',\n",
       "       'California', 'Wyoming', 'CN', 'SK', 'Tennessee', 'Maine', 'IN',\n",
       "       'Massachusetts', 'Kentucky', 'Minnesota', 'IR', 'MA', 'New Mexico',\n",
       "       'Delaware', 'Pennsylvania', 'BO', 'Iowa', 'New Brunswick',\n",
       "       'Colorado', 'TG', 'JP', 'UA', 'Indiana', 'IE', 'DO', 'Ontario',\n",
       "       'CH', 'Florida', 'Missouri', 'South Dakota', 'Arizona', 'Alabama',\n",
       "       'TR', 'Ohio', 'Louisiana', 'Mississippi', 'BE', 'DK', 'Alberta',\n",
       "       'GE', 'Connecticut', 'TW', 'KZ', 'JO', 'Saskatchewan', 'KY', 'SG',\n",
       "       'LB', 'ID', 'IT', 'MY', 'Nebraska', 'IQ', 'SA', 'ME', 'VE', 'NP',\n",
       "       'AR', 'IS', 'RS', 'PE', 'PH', 'BR', 'ET', 'KG', 'Idaho', 'AM',\n",
       "       'NI', 'British Columbia', 'Manitoba', 'UY', 'CO', 'EC', 'MW', 'ZA',\n",
       "       'Oregon', 'GT', 'XK', 'BM', 'BY', 'PS', 'ZW', 'Utah',\n",
       "       'Rhode Island', 'KR', 'GH', 'Newfoundland and Labrador', 'VN',\n",
       "       'PY', 'Arkansas', 'Maryland', 'District of Columbia', 'BD', 'SN',\n",
       "       'EG', 'CR', 'PA', 'PK', 'OM', 'IL', 'BH', 'AZ', 'GG', 'AE',\n",
       "       'New Hampshire', 'DZ', 'MC', 'VC', 'BB', 'JM', 'CM', 'NG', 'MU',\n",
       "       'CD', 'Guam', 'IM', 'TH', 'RO', 'TN', 'BJ', 'LI', 'Nova Scotia',\n",
       "       'HN', 'BZ', 'LC', 'TZ', 'KW', 'Nevada', 'Kansas', 'TJ',\n",
       "       'North Dakota', 'FM', 'Vermont', 'FJ', 'MV', 'MG', 'UG', 'BT',\n",
       "       'Puerto Rico', 'Alaska', 'WS', 'SR', 'CK', 'Hawaii', 'ZM', 'RW',\n",
       "       'West Virginia', 'Montana', 'UZ', 'Prince Edward Island', 'MZ',\n",
       "       'AO', 'BW', 'BF', 'MD', 'GM', 'BN', 'QA', 'YE',\n",
       "       'Northwest Territories', 'PT', 'SV', 'NA', 'SC', 'SS', 'SD', 'LA',\n",
       "       'LS', 'SZ', 'BI', 'CU', 'United States Virgin Islands', 'CG', 'MN',\n",
       "       'MM', 'PG', 'KH', 'FO', 'ES', 'GL', 'Yukon', 'VU', 'GR'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloud_with_locs[\"prb_loc\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#https://cloud.google.com/compute/docs/regions-zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "@DeprecationWarning\n",
    "def prb_location_old(df_edges):\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    df_edges[\"prb_loc\"] = \"\"\n",
    "    for index, row in df_edges.iterrows():\n",
    "        prb_number = row[\"prb\"]\n",
    "        response = requests.get(f\"https://atlas.ripe.net/api/v2/probes/{prb_number}/?format=json\")\n",
    "        resp_json = json.loads(response.content.decode(\"utf-8\"))\n",
    "        long, lat = tuple(resp_json[\"geometry\"][\"coordinates\"])\n",
    "        \n",
    "        location = geolocator.reverse(str(lat) + \",\" + str(long), language = 'en')\n",
    "        country = str((location)).split(\",\")[-1]\n",
    "        \n",
    "        if location == \"United States\":\n",
    "            state = str((location)).split(\",\")[-3]\n",
    "            df_edges.loc[index, \"prb_loc\"] = state\n",
    "        else: \n",
    "            df_edges.loc[index, \"prb_loc\"] = country\n",
    "    return df_edges\n",
    "\n",
    "    \n",
    "@DeprecationWarning\n",
    "def intersects_of_prbs_to_csv():\n",
    "\n",
    "    df = pd.read_csv(r\"C:\\Users\\Admin\\Documents\\GitHub\\umass\\api\\latencies\\edge.csv\", index_col= False)\n",
    "    dfs = [df[df[\"prb\"].isin(dic[region])] for region in dic.keys()]\n",
    "    for df in dfs: \n",
    "        for index, row in df.iterrows():\n",
    "            df[\"MinIP_loc\"] = get_location_ipinfo(row[\"MinIP\"])\n",
    "            for i in range(1,6):  \n",
    "                name = f\"otherIP{i}\"\n",
    "                if pd.isna(row[name]):\n",
    "                    continue\n",
    "                location_data = get_location_ipinfo(row[f\"otherIP{i}\"])\n",
    "                df[f\"otherIP{i}_loc\"] = location_data\n",
    "    concated = pd.concat([df for df in dfs], ignore_index=True)\n",
    "    concated.to_csv(r\"C:\\Users\\Admin\\Documents\\GitHub\\umass\\api\\latencies\\edge_processed4.csv\", index= False)\n",
    "\n",
    "@DeprecationWarning\n",
    "def singleprocess_prb_location():\n",
    "    df_edges = pd.read_csv(r\"api\\latencies\\edge.csv\", index_col= False)\n",
    "    df_prbs_np_arr = df_edges[\"prb\"].unique()\n",
    "    df_prbs = pd.DataFrame(df_prbs_np_arr, columns=[\"prb\"])\n",
    "    df_prbs = prb_location(df_prbs)\n",
    "    df_prbs.to_csv(r\"api\\latencies\\edge_processed_testing2.csv\", index = False)\n",
    "\n",
    "@DeprecationWarning\n",
    "def multiprocess_prb_location():\n",
    "    df_edges = pd.read_csv(r\"api\\latencies\\edge.csv\", index_col= False)\n",
    "    df_prbs_np_arr = df_edges[\"prb\"].unique()\n",
    "    df_prbs = pd.DataFrame(df_prbs_np_arr, columns=[\"prb\"])\n",
    "    num_processes = multiprocessing.cpu_count() - 1\n",
    "    chunk_size = int(df_prbs.shape[0]/num_processes)\n",
    "    chunks = [df_prbs.iloc[df_prbs.index[i:i + chunk_size]] for i in range(0, df_prbs.shape[0], chunk_size)]\n",
    "    df_prbs = prb_location(df_prbs)\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=num_processes)\n",
    "    result = pool.map(prb_location, chunks)\n",
    "\n",
    "    for i in range(len(result)):\n",
    "    # we can reassign the original dataframe based on the index of each chunk\n",
    "        df_prbs.iloc[result[i].index] = result[i]\n",
    "\n",
    "    df_prbs.to_csv(r\"api\\latencies\\edge_processed_testing2.csv\", index = False)\n",
    "\n",
    "@DeprecationWarning\n",
    "def create_adj_matrix(df):\n",
    "    regions_set = set()\n",
    "    cols = [\"otherIP1_loc\", \"otherIP2_loc\", \"otherIP3_loc\", \"otherIP4_loc\", \"otherIP5_loc\", \"MinIP_loc\"]\n",
    "    for index, row in df.iterrows():\n",
    "        for col in cols:\n",
    "            regions_set.add(str(row[col]))\n",
    "    regions_set.remove(\"None\")\n",
    "    regions_set.remove(\"nan\")\n",
    "\n",
    "    adj = pd.DataFrame(columns = list(regions_set))\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        for col in cols: \n",
    "            lat_col = col.replace(\"_loc\", \"\")\n",
    "            lat_col = lat_col.replace(\"IP\", \"latency\")\n",
    "            region_from = row[col]\n",
    "            region_to = row[\"prb_loc\"]\n",
    "            region_from_idx = adj.columns.get_loc(region_from)\n",
    "            region_to_idx = adj.columns.get_loc(region_to)\n",
    "            \n",
    "            latency = row.loc[lat_col]\n",
    "            adj.iloc[region_from_idx, region_to_idx] = latency\n",
    "            adj.iloc[region_to] = latency\n",
    "    #adj.to_csv(r\"api\\latencies\\adjance_latency.csv\", index=False)\n",
    "    return adj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe6f22945cfc871c9399bf7d9f19a00d7d184a1ba9bcdcec8f1d4899546bde82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
